{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c48e7ed-8582-4b4b-bc7e-28d8c0968fd2",
   "metadata": {},
   "source": [
    "*Universidad de Chile*  \n",
    "*Facultad de Ciencias Físicas y Matemáticas*  \n",
    "*Departamento de Ingeniería Matemática*\n",
    "\n",
    "\n",
    "**MA5701 - Optimización no lineal. Semestre de Otoño 2022**  \n",
    "**Profesor:** Jorge Amaya.    \n",
    "**Auxiliar:** Aldo Gutierrez.     \n",
    "**Ayudantes:** Carolina Chiu, Mariano Vazquez.     \n",
    "**Alumno:** Manuel Torres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49c511c8-3ab2-435e-83ec-75ece88b6704",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numdifftools\n",
      "  Using cached numdifftools-0.9.40-py2.py3-none-any.whl (99 kB)\n",
      "Requirement already satisfied: numpy>=1.9 in c:\\users\\personal\\anaconda3\\lib\\site-packages (from numdifftools) (1.22.4)\n",
      "Collecting algopy>=0.4\n",
      "  Using cached algopy-0.5.7-py3-none-any.whl\n",
      "Requirement already satisfied: scipy>=0.8 in c:\\users\\personal\\anaconda3\\lib\\site-packages (from numdifftools) (1.6.2)\n",
      "Requirement already satisfied: statsmodels>=0.6 in c:\\users\\personal\\anaconda3\\lib\\site-packages (from numdifftools) (0.12.2)\n",
      "Requirement already satisfied: pandas>=0.21 in c:\\users\\personal\\anaconda3\\lib\\site-packages (from statsmodels>=0.6->numdifftools) (1.2.4)\n",
      "Requirement already satisfied: patsy>=0.5 in c:\\users\\personal\\anaconda3\\lib\\site-packages (from statsmodels>=0.6->numdifftools) (0.5.1)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\personal\\anaconda3\\lib\\site-packages (from pandas>=0.21->statsmodels>=0.6->numdifftools) (2021.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\personal\\anaconda3\\lib\\site-packages (from pandas>=0.21->statsmodels>=0.6->numdifftools) (2.8.1)\n",
      "Requirement already satisfied: six in c:\\users\\personal\\anaconda3\\lib\\site-packages (from patsy>=0.5->statsmodels>=0.6->numdifftools) (1.15.0)\n",
      "Installing collected packages: algopy, numdifftools\n",
      "Successfully installed algopy-0.5.7 numdifftools-0.9.40\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# (Des)comentar la primera vez que se hace correr el codigo\n",
    "pip install numdifftools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae23f06c-1625-41ed-93c4-2140cb74ad1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Personal\\anaconda3\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\Personal\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.EL2C6PLE4ZYW3ECEVIV3OXXGRN2NRFM2.gfortran-win_amd64.dll\n",
      "C:\\Users\\Personal\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.WCDJNK7YVMPZQ2ME2ZZHJJRJ3JIKNDB7.gfortran-win_amd64.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    }
   ],
   "source": [
    "# Librerias\n",
    "import numpy as np\n",
    "from numpy import linalg\n",
    "import scipy as sp\n",
    "from scipy.optimize import linprog, minimize, LinearConstraint\n",
    "import numdifftools as nd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4d84416-a75d-4dbc-8bea-800fc262ab70",
   "metadata": {},
   "source": [
    "# Metodo de direcciones admisibles\n",
    "Se busca resolver problemas de optimización de la forma:\n",
    "\\begin{equation*}\n",
    "    \\begin{array}{cc}\n",
    "        (P) & \\min f(x)  \\\\\n",
    "            & Ax \\leq b  \\\\\n",
    "            & Ex = e.\n",
    "    \\end{array}\n",
    "\\end{equation*}\n",
    "\n",
    "$(0)$ Sean $\\varepsilon>0$, $k=0$, $x_{0}\\in\\mathbb{R}^{n}$ tal que $Ax_{0}\\leq b$, $Ex_{0}=e$.\n",
    "        \n",
    "$(1)$ Sea la descomposición\n",
    "\\begin{equation*}\n",
    "    A=\n",
    "    \\begin{bmatrix}\n",
    "        A_{1}\\\\A_{2}\n",
    "    \\end{bmatrix},\\quad\n",
    "    b =\n",
    "    \\begin{bmatrix}\n",
    "        b_{1}\\\\b_{2}\n",
    "    \\end{bmatrix},\n",
    "\\end{equation*}\n",
    "tal que $A_{1}x_{k} = b_{1}$, $A_{2}x_{k} <b_{2}$.\n",
    "        \n",
    "$(2)$ Resolver el problema lineal\n",
    "\\begin{equation*}\n",
    "    (\\mathcal{D}_{k})\\left\\{\n",
    "    \\begin{array}{cl}\n",
    "        \\min        & \\nabla f(x_{k})^{T}d  \\\\\n",
    "        \\text{s.a.} & A_{1}d\\leq0           \\\\\n",
    "                    &   Ed = 0\\\\\n",
    "                    &   -1\\leq d_{j} \\leq 1,\\quad j=1,\\dots,n.\n",
    "    \\end{array}\n",
    "    \\right.\n",
    "\\end{equation*}\n",
    "y sea $d_{k}$ solución de $(\\mathcal{D}_{k})$.     \n",
    "-Si $\\|\\nabla f(x_{k})^{T}d_{k}\\|<\\varepsilon$, entonces parar.    \n",
    "-En caso contrario, ir a $(3)$.\n",
    "\n",
    "\n",
    "$(3)$ Determinar el paso, resolviendo aproximadamente el problema  de minimización unidimensional\n",
    "\\begin{equation*}\n",
    "    (L)\\left\\{\n",
    "    \\begin{array}{cl}\n",
    "        \\min        & f(x_{k}+\\lambda d_{k}) \\\\\n",
    "        \\text{s.a}  & \\lambda\\in[0,\\lambda'_{k}] \n",
    "    \\end{array}\n",
    "    \\right.\n",
    "\\end{equation*}\n",
    "mediate el *método de Armijo*. Se usa\n",
    "\\begin{equation*}\n",
    "    \\lambda'_{k} = \\min\\left\\{\\frac{(b_{2}-A_{2}x_{k})_{i}}{(A_{2}d_{k})_{i}} / (A_{2}d_{k})_{i} > 0\\right\\},\n",
    "\\end{equation*}\n",
    "y se considera $\\lambda'_{k}=+\\infty$ cuando $(A_{2}d_{k})_{i}\\leq0$ para todo $i$.\n",
    "\n",
    "Sea $\\lambda_{k}$ solución del subproblema $(L)$. Hacer:\n",
    "\\begin{equation*}\n",
    "    x_{k+1} = x_{k} + \\lambda_{k}d_{k},\\quad k\\leftarrow k+1\n",
    "\\end{equation*}\n",
    "e ir a $(1)$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "034f3402-e632-4d06-8037-fbbfdd1bff5b",
   "metadata": {},
   "source": [
    "# Implementación del método de direcciones admisibles\n",
    "## Métodos auxiliares\n",
    "Para los pasos $(1)$, $(2)$ y $(3)$ se implementan los siguientes métodos:\n",
    "1. *desigualdades_activas_inactivas* realiza la partición sobre $A$ y $b$.\n",
    "2. *problema_d_k* resuelve el problema $\\mathcal{D}_{k}$.\n",
    "3. *metodo_de_armijo* resuelve el problema $L$ mediante el método de Armijo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "68364d7c-1363-42b9-b837-6bd86329599f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def desigualdades_activas_inactivas(A,b,x):\n",
    "    \"\"\"\n",
    "    -Input: Sistema de inecuaciones Ax <= b.\n",
    "    -Output: A1,A2,b1,b2 typo np.array.\n",
    "    -Descripcion: Particiona el sistema de inecuaciones Ax <= b en las desigualdades\n",
    "    activas y las desigualdades inactivas.\n",
    "    \"\"\"\n",
    "    # Declara los arreglos para guardar la particion\n",
    "    A1,A2,b1,b2 = [],[],[],[]\n",
    "    for i in range(len(A)):\n",
    "        # Igualdades alcanzadas\n",
    "        if np.isclose(A[i]@x, b[i]):\n",
    "            A1.append(A[i].tolist())\n",
    "            b1.append(b[i].tolist())\n",
    "        # Desigualdades que no alcanzan igualdad\n",
    "        elif A[i]@x<b[i]:\n",
    "            A2.append(A[i].tolist())\n",
    "            b2.append(b[i].tolist())\n",
    "    # Output en formato de arreglos\n",
    "    #return = A1,A2,b1,b2 \n",
    "    # Output en formato de arreglos de numpy (se transforman de array a np.array)\n",
    "    return np.array(A1), np.array(A2), np.array(b1), np.array(b2)\n",
    "def problema_d_k(f,xk,A1,E):\n",
    "    \"\"\"\n",
    "    -Input:\n",
    "    -Output:\n",
    "    -Descripcion:\n",
    "    \"\"\"\n",
    "    # Calcula el gradiente de f utilizando la libreria numdifftools\n",
    "    gradiente        = nd.Gradient(f)\n",
    "    # Funcion objetivo: Se define a partir del vector gradiente\n",
    "    funcion_objetivo = lambda d: gradiente(xk)@d\n",
    "    # Cotas para xk\n",
    "    cotas            = tuple([i for i in zip([-1 for _ in range(len(xk))], \n",
    "                                             [1 for _ in range(len(xk))])])\n",
    "    restricciones    = []\n",
    "    restricciones_E  = []\n",
    "    # Si no hay restricciones del estilo Ex = 0\n",
    "    if E is None:\n",
    "        for i in range(len(A1)):\n",
    "            restricciones.append(LinearConstraint(A1,[-np.inf]*A1.shape[0],[0]*A1.shape[0]))\n",
    "    # Si hay restricciones del estilo Ex = 0\n",
    "    else:\n",
    "        for i in range(len(E)):\n",
    "            restricciones_E.append(0)\n",
    "        restricciones.append(LinearConstraint(E,restricciones_E,restricciones_E))\n",
    "    # Metodo optimizador: Se utiliza scipy.optimize.minimize\n",
    "    resultado = minimize(funcion_objetivo,[1]*len(xk),method='trust-constr',bounds=cotas,constraints=restricciones)\n",
    "    argmin    = resultado.x # Output\n",
    "    return argmin\n",
    "def metodo_de_armijo(f,gradiente,xk,dk,A2,b2,A,b):\n",
    "    \"\"\"\n",
    "    -Input:\n",
    "    -Output:\n",
    "    -Descripcion:\n",
    "    \"\"\"\n",
    "    sig = 0.6\n",
    "    h   = 0.01\n",
    "    m   = 1\n",
    "    lambdas = []\n",
    "    uwu     = []\n",
    "    for i in range(b2.shape[0]): \n",
    "        if np.all(A2@dk <= 0) == True:\n",
    "            lambdas.append(np.inf)\n",
    "        elif A2[i]@dk > 0:\n",
    "            uwu.append((b2[i] - np.array(A2[i])@ xk)/(A2[i]@dk))\n",
    "    lambdas.append(min(uwu))    \n",
    "    while h * m <= lambdas[0]:\n",
    "        if f(xk) + sig*m*h*gradiente(xk) @ dk >= f(xk + m*h*dk):\n",
    "            m+=1\n",
    "        else:\n",
    "            if np.all(A@(xk+h*(m-1)*dk) <= b) == True:\n",
    "                return h*(m-1)\n",
    "            else:\n",
    "                m-=1\n",
    "    else:\n",
    "        return lambdas[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3859ac3d-1548-45a8-8f25-9d68c71fe00e",
   "metadata": {},
   "source": [
    "## Método principal\n",
    "A continuación se implementa el algoritmo con apoyo de los métodos auxiliares antes implementados. Recordar que las instancias iniciales necesarias son $\\varepsilon>0$, $k=0$, $x_{0}\\in\\mathbb{R}^{n}$ tal que $Ax_{0}\\leq b$, $Ex_{0}=e$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "6dbaa5bf-b5f1-431b-b84c-e029f519727c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metodo_direcciones_admisibles(eps,x0,f,A,b,E=None,e=None,max_cantidad_iteraciones=100):\n",
    "    \"\"\"\n",
    "    -Input:\n",
    "    -Output:\n",
    "    -Descripcion:\n",
    "    \"\"\"\n",
    "    # Contador de cantidad de iteraciones realizadas / conv = True mientras k no exceda\n",
    "    # la cantidad maxima de iteraciones\n",
    "    k, conv = 0, True  \n",
    "    # Punto inicial (viene propuesto un punto para comenzar junto con el problema)\n",
    "    xk = x0\n",
    "    \"Iteración inicial\"\n",
    "    # Paso (1)\n",
    "    A1, A2, b1, b2 = desigualdades_activas_inactivas(A, b, xk)\n",
    "    # Paso (2)\n",
    "    dk = problema_d_k(f, xk, A1, E)    \n",
    "    \"Iteraciones hasta cumplir la condicion \\|\\nabla f(x_{k})^{T}d_{k}\\|<\\epsilon\"\n",
    "    while np.abs(nd.Gradient(f)(xk) @ dk) > eps:\n",
    "        # Pasada una cantidad maxima de iteraciones se supondra que el problema\n",
    "        # es irresoluble con el metodo de direcciones admisibles.\n",
    "        if k > max_cantidad_iteraciones:\n",
    "            print('Se agotó el máximo de iteraciones ({})'.format(max_iter))\n",
    "            conv = False\n",
    "            break\n",
    "        # Paso (3)\n",
    "        tk = metodo_de_armijo(f, nd.Gradient(f), xk,dk, A2, b2, A, b)\n",
    "        if tk == 0:break        \n",
    "        xk = xk + tk*dk\n",
    "        # Aumenta el contador de iteraciones\n",
    "        k = k+1 \n",
    "        # Paso (1)\n",
    "        A1, A2, b1, b2 = desigualdades_activas_inactivas(A, b, xk)\n",
    "        # Paso (2)\n",
    "        dk = problema_d_k(f, xk, A1, E)\n",
    "    \"Entregar reporte de los resultados\"\n",
    "    print('Resultados:')\n",
    "    if conv:\n",
    "        print('Se alcanzó el óptimo en {} iteraciones'.format(k))\n",
    "        print('Valor óptimo: {}'.format(f(xk)))\n",
    "        print('Solución: {}'.format(xk))\n",
    "    else:\n",
    "        print('Se excede la cantidad máxima de iteraciones.')\n",
    "        print('El valor obtenido antes de alcanzar el máximo de iteraciones es: {}'.format(f(xk)))\n",
    "        print('La solución obtenida antes de alcanzar el máximo de iteraciones es: {}'.format(xk))\n",
    "    output = xk\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d993d37a-0447-4bde-8c66-5503b1fd645e",
   "metadata": {},
   "source": [
    "## Problemas test\n",
    "Se testea el método de direcciones admisibles con los siguientes problemas test:\n",
    "1. Comenzando del punto $(0,2)$,\n",
    "\\begin{equation*}\n",
    "    (P_{1})\\left\\{\n",
    "    \\begin{array}{crcl}\n",
    "        \\min        & 8(x_{1}-6)^{2}+(x_{2}-2)^{4}  &&\\\\\n",
    "        \\text{s.a.} & -x_{1}+2x_{2}             &\\leq& 4\\\\\n",
    "                    & 3x_{1}+2x_{2}             &\\leq& 12\\\\\n",
    "                    & x_{1},x_{2}               &\\geq& 0\n",
    "    \\end{array}\\right.\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "0b7b24fb-99d2-46d9-be04-a02da30f87e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Personal\\anaconda3\\lib\\site-packages\\scipy\\optimize\\_hessian_update_strategy.py:182: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  warn('delta_grad == 0.0. Check if the approximated '\n",
      "C:\\Users\\Personal\\anaconda3\\lib\\site-packages\\scipy\\optimize\\_hessian_update_strategy.py:182: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  warn('delta_grad == 0.0. Check if the approximated '\n",
      "C:\\Users\\Personal\\anaconda3\\lib\\site-packages\\scipy\\optimize\\_hessian_update_strategy.py:182: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  warn('delta_grad == 0.0. Check if the approximated '\n",
      "C:\\Users\\Personal\\anaconda3\\lib\\site-packages\\scipy\\optimize\\_hessian_update_strategy.py:182: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  warn('delta_grad == 0.0. Check if the approximated '\n",
      "C:\\Users\\Personal\\anaconda3\\lib\\site-packages\\scipy\\optimize\\_hessian_update_strategy.py:182: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  warn('delta_grad == 0.0. Check if the approximated '\n",
      "C:\\Users\\Personal\\anaconda3\\lib\\site-packages\\scipy\\optimize\\_hessian_update_strategy.py:182: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  warn('delta_grad == 0.0. Check if the approximated '\n",
      "C:\\Users\\Personal\\anaconda3\\lib\\site-packages\\scipy\\optimize\\_hessian_update_strategy.py:182: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  warn('delta_grad == 0.0. Check if the approximated '\n",
      "C:\\Users\\Personal\\anaconda3\\lib\\site-packages\\scipy\\optimize\\_hessian_update_strategy.py:182: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  warn('delta_grad == 0.0. Check if the approximated '\n",
      "C:\\Users\\Personal\\anaconda3\\lib\\site-packages\\scipy\\optimize\\_hessian_update_strategy.py:182: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  warn('delta_grad == 0.0. Check if the approximated '\n",
      "C:\\Users\\Personal\\anaconda3\\lib\\site-packages\\scipy\\optimize\\_hessian_update_strategy.py:182: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  warn('delta_grad == 0.0. Check if the approximated '\n",
      "C:\\Users\\Personal\\anaconda3\\lib\\site-packages\\scipy\\optimize\\_hessian_update_strategy.py:182: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  warn('delta_grad == 0.0. Check if the approximated '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados:\n",
      "Se alcanzó el óptimo en 3 iteraciones\n",
      "Valor óptimo: 46.9041227202609\n",
      "Solución: [3.85346355 0.21980435]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Personal\\anaconda3\\lib\\site-packages\\scipy\\optimize\\_hessian_update_strategy.py:182: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  warn('delta_grad == 0.0. Check if the approximated '\n",
      "C:\\Users\\Personal\\anaconda3\\lib\\site-packages\\scipy\\optimize\\_hessian_update_strategy.py:182: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  warn('delta_grad == 0.0. Check if the approximated '\n",
      "C:\\Users\\Personal\\anaconda3\\lib\\site-packages\\scipy\\optimize\\_hessian_update_strategy.py:182: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  warn('delta_grad == 0.0. Check if the approximated '\n"
     ]
    }
   ],
   "source": [
    "\"Problema 1 - Test\"\n",
    "# Punto inicial\n",
    "x0 = np.array([0,2])\n",
    "# Problema P_1\n",
    "f = lambda x : 8*(x[0] - 6)**2 + (x[1] - 2)**4\n",
    "A = np.array([[-1, 2], [3, 2], [-1, 0], [0, -1]])\n",
    "b = np.array([4,12,0,0])\n",
    "# Metodo de direcciones admisibles sobre P1\n",
    "sol1 = metodo_direcciones_admisibles(0.001,x0,f,A,b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37d7e3ac-eb09-4eb8-ac46-77be1a50485e",
   "metadata": {},
   "source": [
    "2. Comenzando del punto $(2,2,3,2)$,\n",
    "\\begin{equation*}\n",
    "    (P_{2})\\left\\{\n",
    "    \\begin{array}{crcl}\n",
    "        \\min        & x_{1}^{4}-2x_{2}^{2}+10x_{1}x_{2}^{2}+x_{4}^{2}  &&\\\\\n",
    "        \\text{s.a.} & x_{1}+x_{2}-x_{3}             &=& 1\\\\\n",
    "                    & x_{1}                         &=& 4\\\\\n",
    "                    & x_{1}+x_{4}                   &=& 0\\\\\n",
    "                    & x_{1},x_{2},x_{3},x_{4}       &\\geq& 0\n",
    "    \\end{array}\\right.\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "25ddd869-e479-4cd4-a62d-3b9a07e29026",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Personal\\anaconda3\\lib\\site-packages\\scipy\\optimize\\_hessian_update_strategy.py:182: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  warn('delta_grad == 0.0. Check if the approximated '\n",
      "C:\\Users\\Personal\\anaconda3\\lib\\site-packages\\scipy\\optimize\\_hessian_update_strategy.py:182: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  warn('delta_grad == 0.0. Check if the approximated '\n",
      "C:\\Users\\Personal\\anaconda3\\lib\\site-packages\\scipy\\optimize\\_hessian_update_strategy.py:182: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  warn('delta_grad == 0.0. Check if the approximated '\n",
      "C:\\Users\\Personal\\anaconda3\\lib\\site-packages\\scipy\\optimize\\_hessian_update_strategy.py:182: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  warn('delta_grad == 0.0. Check if the approximated '\n",
      "C:\\Users\\Personal\\anaconda3\\lib\\site-packages\\scipy\\optimize\\_hessian_update_strategy.py:182: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  warn('delta_grad == 0.0. Check if the approximated '\n",
      "C:\\Users\\Personal\\anaconda3\\lib\\site-packages\\scipy\\optimize\\_hessian_update_strategy.py:182: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  warn('delta_grad == 0.0. Check if the approximated '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados:\n",
      "Se alcanzó el óptimo en 5 iteraciones\n",
      "Valor óptimo: 13.047127462172996\n",
      "Solución: [0.5358624  0.5358624  0.07172479 3.4641376 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Personal\\anaconda3\\lib\\site-packages\\scipy\\optimize\\_hessian_update_strategy.py:182: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  warn('delta_grad == 0.0. Check if the approximated '\n"
     ]
    }
   ],
   "source": [
    "\"Problema 2 - Test\"\n",
    "# Punto inicial\n",
    "x0 = np.array([2, 2, 3, 2])\n",
    "# Problema P_2\n",
    "g = lambda x : x[0]**4 - 2*x[1]**2 + 10*x[0]*x[1]**2 + x[3]**2\n",
    "A = np.array([[-1,0,0,0], [0,-1,0,0], [0,0,-1,0], [0,0,0,-1]])\n",
    "E = np.array([[1,1,-1,0], [1,0,0,1], [1,-1,0,0]])\n",
    "b = np.array([0, 0, 0, 0])\n",
    "e = np.array([1, 4, 0])\n",
    "# Metodo de direcciones admisibles sobre P2\n",
    "sol2 = metodo_direcciones_admisibles(0.1,x0,g,A,b,E,e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da5f4040-4909-4121-bd15-8687e509e675",
   "metadata": {},
   "source": [
    "# Referencias\n",
    "- Numdifftools’ documentation: https://numdifftools.readthedocs.io/en/latest/index.html (WebPage), https://github.com/pbrod/numdifftools (GitHub).\n",
    "- Numerical Optimization Algorithms: Step Size Via the Armijo Rule: https://www.youtube.com/watch?v=Uz3B9fVb4LQ (Tutorial).\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
